# -*- coding: utf-8 -*-
"""Classificacao.DeepLearning.FotosFlores(GoogleDrive).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YY-uY3n-UOzjNIAkYzpX3uit499BE0lP
"""

#bibliotecas
import tensorflow
from tensorflow import keras
import matplotlib.pyplot as plt
import numpy as np
import tensorflow_hub as hub
from tensorflow.keras.preprocessing.image import ImageDataGenerator

#pego as fotos no googledrive para trabalhar com elas aqui no Colab
from google.colab import drive
drive.mount('/content/drive')

data_root='/content/drive/My Drive/data_set_flowers/'

#separa as imagens em treino, teste e validação.
TRAINING_DATA_DIR = str(data_root+'flowers_train')#recebe as flores de treino
TEST_DATA_DIR = str(data_root+'flowers_test')#recebe as flores de teste
IMAGE_SHAPE = (200,200)#o tamanho das imagens são 200x200
datagen_kwargs = dict(rescale=1./255, validation_split=.20)#faço a reescala das imagens em 255, e validação de 20%, ai os dados de:
valid_datagen = ImageDataGenerator(**datagen_kwargs)#validação
train_datagen = ImageDataGenerator(**datagen_kwargs)#treino
test_datagen = ImageDataGenerator(**datagen_kwargs)#teste e geram os dados de imagem geradas pelo IDG

valid_generator = valid_datagen.flow_from_directory(#pego a partir do diretório do drive
    TRAINING_DATA_DIR,#passo o caminho da pasta
    subset="validation",#passo o conjunto de validação(20% atribuido anteriormente)
    shuffle=True,#embaralha
    target_size=IMAGE_SHAPE,#tamanho da imagem
    classes = ['daisy', 'dandelion', 'rose']#as tres possíveis classes
)

test_generator = test_datagen.flow_from_directory(
    TEST_DATA_DIR,
    target_size=IMAGE_SHAPE,
    classes = ['daisy', 'dandelion', 'rose']
)

train_generator = train_datagen.flow_from_directory(
    TRAINING_DATA_DIR,
    subset="training",
    shuffle=True,
    target_size=IMAGE_SHAPE,
    classes = ['daisy', 'dandelion', 'rose']
)

image_batch_train, label_batch_train = next(iter(train_generator)) #pega o shape do batch através do comando next iter com o gerador de treino
print("Image batch shape: ", image_batch_train.shape)#printa o tamanho cada batch tem 32, 200x200 (tamanho das imagens), 3 ARRAYS(RGB)
print("Label batch shape: ", label_batch_train.shape)#label das classes
dataset_labels = sorted(train_generator.class_indices.items(), key=lambda pair:pair[1])#ordena os itens
dataset_labels = np.array([key.title() for key, value in dataset_labels])#pega as tres classes
print(dataset_labels)

'''modelo = keras.Sequential([hub.KerasLayer("https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4",
output_shape=[1280],
trainable=False),
keras.layers.Dense(256, activation=tensorflow.nn.relu),
#testar com mais uma--> keras.layers.Dense(128, activation=tensorflow.nn.relu),
keras.layers.Dense(train_generator.num_classes, activation='softmax')
])

'''
modelo = keras.Sequential([keras.layers.Flatten(input_shape=(200, 200, 3)),#cada imagem 200x200 com padrão RGB
keras.layers.Dense(256, activation=tensorflow.nn.relu),#deep learning
keras.layers.Dense(128, activation=tensorflow.nn.relu),
keras.layers.Dense(64, activation=tensorflow.nn.relu),
keras.layers.Dense(train_generator.num_classes, activation='softmax')#saida
])

#compila o modelo 
modelo.compile(
optimizer='Adam',
loss='categorical_crossentropy',
metrics=['acc'])

#passos, quantos passos por epoca
steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)
#validações por época
val_steps_per_epoch = np.ceil(valid_generator.samples/valid_generator.batch_size)


hist = modelo.fit(
train_generator,#recebe os dados de train_generator
epochs=10,#10 epocas
verbose=1,#imprime
steps_per_epoch=steps_per_epoch,#espaços por época
validation_data=valid_generator,#dados de validação que ele vai receber
validation_steps=val_steps_per_epoch).history #validação por época

#salva o modelo
SAVED_MODEL = "/content/drive/My Drive/data_set_flowers/saved_models"
modelo.save(SAVED_MODEL)
model = keras.models.load_model(SAVED_MODEL)

val_image_batch, val_label_batch = next(iter(test_generator))#separo novamente os batch, recebendo os test_generator
true_label_ids = np.argmax(val_label_batch, axis=-1)#valores dos labels verdadeiros
print("Validation batch shape:", val_image_batch.shape)#imprime o shape de validação

model.predict(val_image_batch)#faz o predict do val_image_batch

#aqui carrego o modelo e peço para avaliar
#passando os dados das imagens e as classes
perda_teste, acuracia_teste=model.evaluate(val_image_batch, val_label_batch)
print('Perda do teste', perda_teste)#imprimo as perdas
print('Acurácia do teste', acuracia_teste)#imprimo as acurácias